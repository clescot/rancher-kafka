# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# see kafka.server.KafkaConfig for additional details and defaults

############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
{{ $containerName := getv "/self/container/name"}}
broker.id={{getv "/self/container/create_index"}}
auto.leader.rebalance.enable={{if exists "/self/service/metadata/auto_leader_rebalance"}}{{ getv "/self/service/metadata/auto_leader_rebalance"}}{{else}}true{{end}}

# Replication
auto.create.topics.enable={{if exists "/self/service/metadata/auto_create_topics_enable"}}{{ getv "/self/service/metadata/auto_create_topics_enable"}}{{else}}true{{end}}
default.replication.factor={{if exists "/self/service/metadata/default_replication_factor"}}{{ getv "/self/service/metadata/default_replication_factor"}}{{else}}3{{end}}

# Hostname the broker will advertise to consumers. If not set, kafka will use the value returned
# from InetAddress.getLocalHost().  If there are multiple interfaces getLocalHost
# may not be what you want.
advertised.host.name={{if exists "/self/service/metadata/accessible_from_public_ip"}}{{getv "/self/host/agent_ip" }}{{else}}{{getv "/self/container/primary_ip" }}{{end}}

compression.type={{if exists "/self/service/metadata/compression_type"}}{{ getv "/self/service/metadata/compression_type"}}{{else}}producer{{end}}

delete.topic.enable={{if exists "/self/service/metadata/delete_topic_enable"}}{{ getv "/self/service/metadata/delete_topic_enable"}}{{else}}true{{end}}

host.name={{getv "/self/container/primary_ip" }}

############################# Socket Server Settings #############################

# The port the socket server listens on
port={{if exists "/self/service/metadata/port"}}{{getv "/self/service/metadata/port" }}{{else}}9092{{end}}
advertised.port={{if exists "/self/service/metadata/port"}}{{getv "/self/service/metadata/port" }}{{else}}9092{{end}}

############################# Log Basics #############################

# The directory under which to store log files
log.dir=/data/kafka-logs-{{getv "/self/container/create_index"}}
log.dirs=/data/kafka-logs-{{getv "/self/container/create_index"}}

# The number of logical partitions per topic per server. More partitions allow greater parallelism
# for consumption, but also mean more files.
num.partitions={{if exists "/self/service/metadata/partitions"}}{{getv "/self/service/metadata/partitions" }}{{else}}3{{end}}

############################# Log Retention Policy #############################

# The following configurations control the disposal of log segments. The policy can
# be set to delete segments after a period of time, or after a given size has accumulated.
# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens
# from the end of the log.

# The minimum age of a log file to be eligible for deletion
log.retention.hours={{if exists "/self/service/metadata/log_retention_hours"}}{{getv "/self/service/metadata/log_retention_hours" }}{{else}}168{{end}}
log.cleaner.enable={{if exists "/self/service/metadata/log_cleaner_enable"}}{{getv "/self/service/metadata/log_cleaner_enable" }}{{else}}false{{end}}
############################# Zookeeper #############################

# Zk connection string (see zk docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect={{range ls "/services/zookeeper/containers"}}{{ $containerName := getv (printf "/services/zookeeper/containers/%s" .)}}{{getv (printf "/containers/%s/primary_ip" $containerName)}}:2181,{{end}}

zookeeper.connection.timeout.ms=10000
controlled.shutdown.enable=true
zookeeper.session.timeout.ms=10000

